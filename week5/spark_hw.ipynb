{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f53c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/20 21:19:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48470c1c",
   "metadata": {},
   "source": [
    "# Homework 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84f2b5",
   "metadata": {},
   "source": [
    "**Question 1: \n",
    "Install Spark and PySpark**\n",
    "\n",
    "Install Spark\n",
    "Run PySpark\n",
    "Create a local spark session\n",
    "Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "\n",
    "3.3.2\n",
    "2.1.4\n",
    "1.2.3\n",
    "5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae754cc",
   "metadata": {},
   "source": [
    "**Answer:** 3.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b38ec2",
   "metadata": {},
   "source": [
    "**Question 2:\n",
    "HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.\n",
    "We will use this dataset for all the remaining questions.\n",
    "Repartition it to 12 partitions and save it to parquet.\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 2MB\n",
    "- 24MB\n",
    "- 100MB\n",
    "- 250MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff19e02",
   "metadata": {},
   "source": [
    "**Answer:** 55 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36e791",
   "metadata": {},
   "source": [
    "**Question 3:\n",
    "Count records**\n",
    "\n",
    "How many taxi trips were there on June 15?\n",
    "\n",
    "Consider only trips that started on June 15.\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 50,982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca946632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "    .parquet('fhvhv_tripdata_2021-06.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a398ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ac49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed12580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwell5060/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7325d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select count(1) from trips_data\n",
    "where to_date(pickup_datetime) = '2021-06-15'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe714b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f430af",
   "metadata": {},
   "source": [
    "**Answer:** 452470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e536dd",
   "metadata": {},
   "source": [
    "**Question 4:\n",
    "Longest trip for each day**\n",
    "\n",
    "Now calculate the duration for each trip.\n",
    "How long was the longest trip in Hours?\n",
    "\n",
    "- 66.87 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0122ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select to_date(pickup_datetime), sum(trip_miles) from trips_data\n",
    "group by to_date(pickup_datetime)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff12eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------+\n",
      "|to_date(pickup_datetime)|   sum(trip_miles)|\n",
      "+------------------------+------------------+\n",
      "|              2021-06-22|2197405.2539999997|\n",
      "|              2021-06-04|2523189.7269999995|\n",
      "|              2021-06-20| 2641823.867999995|\n",
      "|              2021-06-27|2693720.9590000007|\n",
      "|              2021-06-28|2166664.5040000016|\n",
      "|              2021-06-01|2065845.4230000004|\n",
      "|              2021-06-17|       2470517.193|\n",
      "|              2021-06-13|2648553.6839999994|\n",
      "|              2021-06-19| 2970106.103999991|\n",
      "|              2021-06-02|2186604.9149999963|\n",
      "|              2021-06-08| 2122038.780000001|\n",
      "|              2021-06-26|2934053.7440000055|\n",
      "|              2021-06-14|2081557.1319999977|\n",
      "|              2021-06-09|2254572.4190000035|\n",
      "|              2021-06-29| 2196246.443999998|\n",
      "|              2021-06-07|2094369.2080000006|\n",
      "|              2021-06-06|2716537.8849999965|\n",
      "|              2021-06-11|2623803.3680000007|\n",
      "|              2021-06-18|2657914.6879999954|\n",
      "|              2021-06-21| 2105493.538999997|\n",
      "+------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814bb41",
   "metadata": {},
   "source": [
    "is trip_time EQUALS dropoff_datetime-pickup_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf4d3c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+---------+\n",
      "|(unix_timestamp(dropoff_datetime, yyyy-MM-dd HH:mm:ss) - unix_timestamp(pickup_datetime, yyyy-MM-dd HH:mm:ss))|trip_time|\n",
      "+--------------------------------------------------------------------------------------------------------------+---------+\n",
      "|                                                                                                           656|      656|\n",
      "|                                                                                                          1682|     1682|\n",
      "|                                                                                                           332|      332|\n",
      "|                                                                                                           645|      645|\n",
      "|                                                                                                          1111|     1111|\n",
      "|                                                                                                           528|      528|\n",
      "|                                                                                                           939|      939|\n",
      "|                                                                                                          1175|     1175|\n",
      "|                                                                                                          1159|     1159|\n",
      "|                                                                                                           853|      853|\n",
      "|                                                                                                          2466|     2466|\n",
      "|                                                                                                          1015|     1015|\n",
      "|                                                                                                           497|      497|\n",
      "|                                                                                                          1315|     1315|\n",
      "|                                                                                                           386|      386|\n",
      "|                                                                                                           394|      394|\n",
      "|                                                                                                           476|      476|\n",
      "|                                                                                                          1222|     1222|\n",
      "|                                                                                                          2348|     2348|\n",
      "|                                                                                                           560|      560|\n",
      "+--------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select (unix_timestamp(dropoff_datetime)-unix_timestamp(pickup_datetime)), trip_time from trips_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb76655",
   "metadata": {},
   "source": [
    "Now I'm ready to solve this puzzle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82a64a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      date|     max_trip_time|\n",
      "+----------+------------------+\n",
      "|2021-06-25|  66.8788888888889|\n",
      "|2021-06-22|25.549722222222222|\n",
      "|2021-06-27|19.980833333333333|\n",
      "|2021-06-26|18.197222222222223|\n",
      "|2021-06-23|16.466944444444444|\n",
      "|2021-06-24|13.909722222222221|\n",
      "|2021-06-04|             11.67|\n",
      "|2021-06-20|10.984444444444444|\n",
      "|2021-06-01|           10.2675|\n",
      "|2021-06-28| 9.966388888888888|\n",
      "|2021-06-18| 9.624444444444444|\n",
      "|2021-06-08| 9.480277777777777|\n",
      "|2021-06-11| 9.471388888888889|\n",
      "|2021-06-15| 9.402222222222223|\n",
      "|2021-06-03| 9.365833333333333|\n",
      "|2021-06-19| 9.106944444444444|\n",
      "|2021-06-30| 9.056111111111111|\n",
      "|2021-06-09| 9.030277777777778|\n",
      "|2021-06-17| 8.774166666666666|\n",
      "|2021-06-29| 8.571666666666667|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select to_date(pickup_datetime) as date, max(trip_time/3600) as max_trip_time from trips_data\n",
    "group by 1\n",
    "order by 2 desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6079e191",
   "metadata": {},
   "source": [
    "**Answer:** 66.87 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20786473",
   "metadata": {},
   "source": [
    "**Question 5:\n",
    "User Interface**\n",
    "\n",
    "Spark’s User Interface which shows application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfea4f",
   "metadata": {},
   "source": [
    "**Answer:** 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc42c3",
   "metadata": {},
   "source": [
    "**Question 6:\n",
    "Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- Crown Heights North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270bf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2398ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4ff2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select * from zones\n",
    "limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2d7c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d16d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                 zon|count(1)|\n",
      "+--------------------+--------+\n",
      "| Crown Heights North|  231279|\n",
      "|        East Village|  221244|\n",
      "|         JFK Airport|  188867|\n",
      "|      Bushwick South|  187929|\n",
      "|       East New York|  186780|\n",
      "|TriBeCa/Civic Center|  164344|\n",
      "|   LaGuardia Airport|  161596|\n",
      "|            Union Sq|  158937|\n",
      "|        West Village|  154698|\n",
      "|             Astoria|  152493|\n",
      "|     Lower East Side|  151020|\n",
      "|        East Chelsea|  147673|\n",
      "|Central Harlem North|  146402|\n",
      "|Williamsburg (Nor...|  143683|\n",
      "|          Park Slope|  143594|\n",
      "|  Stuyvesant Heights|  141427|\n",
      "|        Clinton East|  139611|\n",
      "|West Chelsea/Huds...|  139431|\n",
      "|             Bedford|  138428|\n",
      "|         Murray Hill|  137879|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "select zon.Zone as zon, count(*) from trips_data trd\n",
    "left join zones zon on trd.PULocationID = zon.LocationID\n",
    "group by 1\n",
    "order by 2 desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ac9e7",
   "metadata": {},
   "source": [
    "**Answer:** Crown Heights North"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
